<h1 align="center">Md Milon Sarker</h1>
<p align="center">Lubbock, TX | milon.sarker@gmail.com | (806) 470-9458 | www.linkedin.com/in/milonsarker/ | www.github.com/milonsarker</p>

## SUMMARY

Looking to help data-driven organizations by utilizing my 6+ years of real-world complex problem-solving experiences specializing in high-scale analytic workloads running on Oracle and Hadoop Ecosystem, with a strong understanding of each level of the Enterprise Data Warehouse and Analytics ecosystem with a solid understanding of end-to-end needs.

## TECHNICAL SKILLS
<table border="0">
<tr><td>

- Python
- PL/SQL (Oracle)
- Shell Script
- MySQL

</td><td>

- Python
- PL/SQL (Oracle)
- Shell Script
- MySQL

</td><td>

- Apache Airflow
- Data structures 
- Algorithm
- AWS - Redshift

</td><td>

 - AWS – Glue
 - AWS – Databases
 - AWS – Sagemaker
 - AWS – EC2

</td></tr>
</table>

## EXPERIENCE
<h3><span style="display: block;">Robi Axiata Limited</span><span style="float: right;">Dhaka, Bangladesh</span></h3>
<p style="padding-left: 1em;"><span style="display: block;"><i>Senior Data Engineer</i></span><span style="float: right;">October 2019 – August 2022</span></p>

  - Defined, developed and managed the EDW and Analytics architecture to meet Enterprise’s Business analytics and reporting needs.
  - Designed, developed and collaborated on Big Data ETL project to transform data loading in Hadoop Ecosystem. 
  - Built ETL data pipeline to process around 50 billion records and 12 TB data per day in Hadoop using PySpark.
  - Developed near real time ETL process which helped on real time reporting using Python, PL/SQL and Shell Scripts. 
  - Created complex ETL mappings and workflows to integrate new systems, review query performance, optimize code and create processes, procedures and tools to validate data post ETL.
  - Developed and managed APIs using Python FastAPI. Used numerous APIs for building data pipelines.
  - Developed POC projects using KAFKA/Apache Flink and AWS Technologies using AWS Redshift, Glue, S3, EC2. 

<p style="padding-left: 1em;"><span style="display: block;"><i>Data Engineer</i></span><span style="float: right;">March 2017 – October 2019</span></p>

  - Developed data live loading framework using parallel processing, which reduced processing time from 12-15 hours to 2 hours using Python, PL/SQL and Shell Scripts.
  - Defined and implemented ETL processes to load data from different source systems into the data warehouse.
  - Scheduled and Managed workflows using Talend ETL Tool/Apache Airflow/Oracle Chains. 
  - Analyzed source system’s data to identify any potential data quality issues.
  - Investigated, resolved, fine-tuned data loading processes and data warehouse performance issues.
  - Performed impact analysis for proposed changes to the data warehouse and analytics architecture.
  - Used Gitlab, Jenkins for Continuous Integration/Continuous Delivery and Deployment(CI/CD). 

<h3><span style="display: block;">Accenture</span><span style="float: right;">Dhaka, Bangladesh</span></h3>
<p style="padding-left: 1em;"><span style="display: block;"><i>Software Engineering Associate</i></span><span style="float: right;">December 2015 – February 2017</span></p>

 - Developed data pipelines and data solutions using CI/CD method following ADM guidelines using Gitlab.
 - Ensured SLA of Mediation Systems Services and day to day operation to meet business requirement and KPI.
 - Created policies and operational guidelines to maintain compliance and security of operations.
 - Provided prompt stakeholder support and support for ad-hoc requirements related to Mediation system. 

## Education

- Degree, School, Year
- ...

## Projects

- [Project 1](link to project 1): Brief description of project 1
- [Project 2](link to project 2): Brief description of project 2
- ...

## Contact Me

- Email: [your email]
- LinkedIn: [link to your LinkedIn]
- GitHub: [link to your GitHub]


<p>
<span style="float: left;">Left aligned text</span>
<span style="float: right;">Right aligned text</span>
</p>